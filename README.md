# Composer-Specific Music Generation with Transformers

This project builds a lightweight, end-to-end pipeline to generate stylistically faithful piano music in the style of Frédéric Chopin, using Encodec audio tokens and a GPT-style Transformer architecture. The model learns directly from audio data and produces output that reflects expressive nuances lost in MIDI-based models.

---

## Project Folder Structure

```
Transformer_ECS111/
│
├── raw_data/                     # Place your uncompressed WAV audio here
│   └── chopin/                   # Folder named after the composer, e.g., 'chopin'
│       └── *.wav                 # All raw WAV files (48 kHz preferred)
│
├── token_data/                   # Will contain token files after tokenization
│
├── token_jsonl/                  # Metadata files with paths/labels per token file
│
├── model_results_chopin/        # Folder where model checkpoints will be saved
│
├── generated_clips/             # Folder for storing generated audio files
│
├── plots/                        # Optional: stores entropy/debugging plots
│
├── 1_audio_preprocessing.py     # Preprocess WAV files (trims silence, pads)
├── 2_Tokenization.py            # Tokenizes preprocessed audio into Encodec tokens
├── 3_data_preparation.py        # Generates JSONL file linking token files and labels
├── 4_Transformer.py             # Trains a multi-codebook GPT Transformer on the tokens
├── 5_MusicPrediction.py         # Generates music from learned model using temperature sampling
├── 100_resume_training.py       # Resumes training from checkpoint
│
├── requirements.txt             # Dependencies list
└── README.md
```

---

## Installation

```bash
# Clone the repo
$ git clone https://github.com/<your-name>/Transformer_ECS111.git
$ cd Transformer_ECS111

# Create and activate a new environment (optional but recommended)
$ conda create -n musicgen python=3.10
$ conda activate musicgen

# Install dependencies
$ pip install -r requirements.txt
```

---

## Step-by-Step Pipeline

### 1. Audio Preprocessing (`1_audio_preprocessing.py`)

* What it does: Trims silence, pads audio to multiple of 10s, and normalizes.
* Input: `raw_data/chopin/*.wav`
* Output: Preprocessed files saved in-place.

### 2. Tokenization (`2_Tokenization.py`)

* What it does: Encodes audio using Encodec (48 kHz, 8-codebook quantization).
* Output: `token_data/*.th` files.

### 3. Metadata Generation (`3_data_preparation.py`)

* What it does: Links token file paths with composer label (e.g., "chopin").
* Output: JSONL file in `token_jsonl/` used for training.

### 4. Transformer Training (`4_Transformer.py`)

* What it does: Trains a decoder-only Transformer with 8 layers, 8 heads, and separate output heads for each of the 8 codebooks.
* Output: Model checkpoints in `model_results_chopin/`
* Result: Model learns stylistic cues (rubato, phrasing) from Chopin tokens.

### 5. Music Generation (`5_MusicPrediction.py`)

* What it does: Generates music from 1-token prompt (optionally with a 3s seed).
* Uses top-p (0.9), temp=1.0, repetition penalty γ=1.015, dynamic entropy boosting.
* Output: WAV files stored in `generated_clips/`

### 6. Resume Training (`100_resume_training.py`)

* Optional: Allows continuing training from a checkpoint.

---

## Evaluation Protocol

We conducted a perceptual evaluation using 14 human participants with the music generated by the model that trained on 47 hours of music from Chopin. Each listener rated 1-minute clips on a scale of 1 (clearly fake) to 10 (clearly real Chopin).

* Real Chopin recordings scored **9.1 ± 0.8**.
* Our generated outputs scored **4.3 ± 1.2**, indicating that while stylistic elements like dynamics and phrasing were learned, the model still lacked realism in rhythm, fidelity, and long-term structure.

---

## Notes & Limitations

* Folder names must match: `raw_data/chopin/`, `token_data/`, etc.
* Labels in JSONL must match composer name.
* Make sure to manually adjust parameters in scripts if using a different artist name.
* All outputs will reflect `chopin` unless otherwise specified.

---

## Requirements

Dependencies are listed in `requirements.txt`. Install them with:

```bash
pip install -r requirements.txt
```

If you want to regenerate this file, use the command:

```bash
pip freeze > requirements.txt
```

---

## Data Source

data can be downloaded by open source website for music, for example the Internet Archive. Note that these music need to be stored in the data_raw folder

Internet Archive. (n.d.). Audio Archive. https://archive.org/details/audio 

For bugs or questions, please open an issue on GitHub or email the project maintainer.
